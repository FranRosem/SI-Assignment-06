{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dkBuncKvAkW-"
      },
      "source": [
        "## Assignment 06\n",
        "\n",
        "**Students:**\n",
        "- Franklin Ruben Rosembluth Prado\n",
        "- Sharon Sarai Maygua Mendiola"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "esEIJSV_AkXF"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reinforcement learning** is an area of Artificial Intelligence that helps an agent perform determined actions in order to reach a particular goal.\n",
        "\n",
        "This method can have different applications such as self-driving cars or playing games:\n",
        "\n",
        "\n",
        "- Reinforcement learning consists in having an agent that can be in different states, and perform certain actions in each given state.\n",
        "\n",
        "- Making an action in a given state results in a new state for the agent. The agent must have a goal state that can be reached by performing a list of defined actions, the idea is to teach the agent how to reach the goal state, the agent must learn to make decisions regarding which action to take in each state.\n",
        "\n",
        "- The most important thing in the algorithm is the way it saves the information of which actions can have a good or bad reward, and which actions will really lead the agent to the goal state.\n",
        "\n",
        "- The algorithm known as Bellman algorithm has a Q-table in order to store information of each state, and for each state the expected reward of each action the agent can take in.\n",
        "\n",
        "- An agent must be rewarded or penalized in order to make him learn better actions.\n",
        "\n",
        "- This expected reward is a metric that tells the agent how good or bad it is to take each of the possible actions that can do, As the agent learns, these rewards change, until the agent reaches the point where the reward is maximized and it cannot improve more, when this happens the agent has reached an **optimal policy**.\n",
        "\n",
        "- **The optimal policy** can be defined as the best possible actions that the agent can make in each state in order to maximize the reward.\n",
        "\n",
        "- The main objective of Reinforcement Learning is finding the optimal policy in the problem.\n",
        "\n",
        "For this practice, we will apply RL using Q-learning, The environment consists on Harry Potter (agent) going through the **\"Prison of Azkavan\"** in order to save Sirius Black (goal), the representation of the prison has 9 columns and 7 rows.\n",
        "\n",
        "Harry starts at position (1,1) and Sirius is prisioned on (7,4). In columns 3, 4, and 5 exists windy columns going from south to north that makes Harry in hurry and difficult situations to get to Sirius Black."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1A5T0z-8AkXG"
      },
      "source": [
        "# Problem with Q-learning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NSnx3ItuAkXH"
      },
      "source": [
        "1. How do you plan to resolve this problem using Q-learning? - ¿Cómo planeas resolver el problema usando q-learning?\n",
        "\n",
        "- To implement Q-learning with the problem, we need to analyze what type of rewards the agent will receive according to the states it may have through the iteration.\n",
        "- Finding which would be the best values to obtain an optimal policy that allows the agent to make better decisions.\n",
        "- We started giving the agent this goals:\n",
        "- **-10** from Falling out of the board, **-1** for every step that the agent makes and **100** if the agent reaches the goal state.\n",
        "- We thought about the values that the agent could obtain when a is making a step. Firstly we use negative rewards (penalize) with the idea that if the agent falls of the map or makes bad steps, the agent would lose rewards after reaching the goal, that's why instead of concentrating on finding more unuseful path, the agent should go to the goal directly.\n",
        "\n",
        "- The code that we suggest to resolve this particular problem is here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P3SQMYuAkXI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "import random\n",
        "from copy import copy\n",
        "from termcolor import colored, cprint\n",
        "import time\n",
        "import math\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import Normalize, ListedColormap\n",
        "from PIL import Image"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm_JGMRCAq4e"
      },
      "source": [
        "# Create the environment\n",
        "\n",
        "The \"create_map\" function, creates a map that is represented as a two-dimensional array. The values used are: 0 for empty space, 1 for the start position and 2 for the target position. This function is useful because it generates a learning environment where a learning reinforcement agent must traverse from the start position to the target position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJgG3y0UAkXL"
      },
      "outputs": [],
      "source": [
        "# 0 = empty_space; 1 = init_pos; 2 = goal_pos\n",
        "def create_map(size, init_position, goal_pos):\n",
        "    map = np.zeros((size[1], size[0]), dtype=np.int)\n",
        "    map[init_position[1], init_position[0]] = 1\n",
        "    map[goal_pos[1], goal_pos[0]] = 2\n",
        "    return map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peSIgh8gAkXM",
        "outputId": "9ab83fd1-88eb-44e0-a408-cca8a6c4c439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "map_size = (9, 7)\n",
        "init_pos = (1, 1)\n",
        "goal_pos = (7, 4)\n",
        "map = create_map(map_size, init_pos, goal_pos)\n",
        "print(map)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UhkEb2IwAy22"
      },
      "source": [
        "Initialization of the action space, the state space, and creation of the Q table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8KiHkEhAkXN",
        "outputId": "9b92e970-46b1-4539-b338-52ac50b90909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8 63\n",
            "(63, 8)\n"
          ]
        }
      ],
      "source": [
        "action_space_size = 8 # UP, RIGHT, DOWN, LEFT UP_RIGHT, ..., DOWN_LEFT\n",
        "state_space_size = map_size[0] * map_size[1] # AREA\n",
        "print(action_space_size, state_space_size)\n",
        "\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "\n",
        "print(q_table.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LngeuU3MAkXO",
        "outputId": "65b5cfa3-8f4e-45fb-eb1f-2dcd6c9f4396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "down\n"
          ]
        }
      ],
      "source": [
        "# actions_dict = {0: 'up', 1: 'down', 2: 'left', 3: 'right', 4: 'up_right', 5: 'up_left', 6: 'down_right', 7: 'down_left'}\n",
        "actions = ['up', 'down', 'left', 'right', 'up_right', 'up_left', 'down_right', 'down_left']\n",
        "print(actions[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5Jv2VcdAkXP",
        "outputId": "06f1e5cb-2c4e-4ca4-9f11-c1122054ad76"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def show_map_3(map):\n",
        "    row_labels, col_labels = range(map.shape[0]+1), range(map.shape[1]+1)\n",
        "    cmap = ListedColormap(['white', 'yellowgreen', 'blueviolet'])\n",
        "    norm = Normalize(vmin=0, vmax=2)\n",
        "    plt.imshow(map, cmap=cmap, norm=norm)\n",
        "    plt.xticks(np.arange(len(col_labels)-1) + 0.5, col_labels[1:])\n",
        "    plt.yticks(np.arange(len(row_labels)-1) + 0.5, row_labels[1:])\n",
        "    plt.grid(color='k', linewidth=1)\n",
        "    init = np.where(map == 1)\n",
        "    plt.text(init[1][0], init[0][0], 'H', ha='center', va='center', color='black', weight='bold', fontsize=15)\n",
        "    goal = np.where(map == 2)\n",
        "    plt.text(goal[1][0], goal[0][0], 'S', ha='center', va='center', color='black', weight='bold', fontsize=15)\n",
        "    plt.show()\n",
        "\n",
        "show_map_3(map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neGJvPmDAkXP",
        "outputId": "07bdff15-7367-47fd-eb6c-7a7a20a6cee0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 370.286x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# actions_dict = {0: 'up', 1: 'down', 2: 'left', 3: 'right', 4: 'up_right', 5: 'up_left', 6: 'down_right', 7: 'down_left'}\n",
        "arrows = ['\\u2191', '\\u2193', '\\u2190', '\\u2192', '\\u2197', '\\u2196', '\\u2198', '\\u2199']\n",
        "\n",
        "def show_map(map):\n",
        "    row_labels, col_labels = range(map.shape[0]), range(map.shape[1])\n",
        "    cmap = ListedColormap(['white', 'blueviolet', 'yellowgreen'])\n",
        "    norm = Normalize(vmin=0, vmax=2)\n",
        "    plt.matshow(map, cmap=cmap, norm=norm)\n",
        "    plt.xticks(col_labels, col_labels)\n",
        "    plt.yticks(row_labels, row_labels)\n",
        "    plt.grid(color='k', linewidth=1)\n",
        "    init = np.where(map == 1)\n",
        "    plt.text(init[1][0], init[0][0], 'H', ha='center', va='center', color='white', weight='bold', backgroundcolor='blueviolet', fontsize=20)\n",
        "    goal = np.where(map == 2)\n",
        "    plt.text(goal[1][0], goal[0][0], 'S', ha='center', va='center', color='white', weight='bold', backgroundcolor='yellowgreen', fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "show_map(map)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aCsyronsAkXQ"
      },
      "source": [
        "Created with help of: https://www.gymlibrary.dev/content/environment_creation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5grIeomAkXR"
      },
      "outputs": [],
      "source": [
        "class AzkabanEnviroment:\n",
        "    def __init__(self, map, init_pos, goal_pos, prob_A=0.9, prob_B=0.8, prob_C=0.9):\n",
        "        self.map = map\n",
        "        self.size = (self.map.shape[1], self.map.shape[0])\n",
        "        self.harry_pos = init_pos\n",
        "        self.sirius_pos = goal_pos\n",
        "        self.reset_map = map\n",
        "        self.reset_harry_pos = init_pos\n",
        "        self.action_space = spaces.Discrete(8)\n",
        "        self.observation_space = spaces.Discrete(self.map.shape[0] * self.map.shape[1])\n",
        "        self.prob_A = prob_A\n",
        "        self.prob_B = prob_B\n",
        "        self.prob_C = prob_C\n",
        "        self._action_to_direction = {\n",
        "            0: 'up', \n",
        "            1: 'down', \n",
        "            2: 'left', \n",
        "            3: 'right', \n",
        "            4: 'up_right', \n",
        "            5: 'up_left', \n",
        "            6: 'down_right', \n",
        "            7: 'down_left'\n",
        "        }\n",
        "        self._rewards = {\n",
        "            \"walk\": -1,\n",
        "            \"fall\": -10,\n",
        "            \"goal\": 100\n",
        "        }\n",
        "    \n",
        "    def get_actions(self, action):\n",
        "        return self._action_to_direction[action]\n",
        "    \n",
        "    def get_rewards(self):\n",
        "        return self._rewards\n",
        "    \n",
        "    def set_rewards(self, walk , fall, goal):\n",
        "        self._rewards = {\n",
        "            \"walk\": walk,\n",
        "            \"fall\": fall,\n",
        "            \"goal\": goal\n",
        "        }\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Harry Position: ({self.harry_pos[0]}, {self.harry_pos[1]})\\n\" + str(self.map)\n",
        "\n",
        "    def render(self):\n",
        "        row_labels, col_labels = range(self.map.shape[0]), range(self.map.shape[1])\n",
        "        cmap = ListedColormap(['white', 'blueviolet', 'yellowgreen'])\n",
        "        norm = Normalize(vmin=0, vmax=2)\n",
        "        plt.matshow(self.map, cmap=cmap, norm=norm)\n",
        "        plt.xticks(col_labels, col_labels)\n",
        "        plt.yticks(row_labels, row_labels)\n",
        "        plt.grid(color='k', linewidth=1)\n",
        "        init = np.where(self.map == 1)\n",
        "        plt.text(init[1][0], init[0][0], 'H', ha='center', va='center', color='white', weight='bold', fontsize=15)\n",
        "        goal = np.where(self.map == 2)\n",
        "        plt.text(goal[1][0], goal[0][0], 'S', ha='center', va='center', color='white', weight='bold', fontsize=15)\n",
        "        plt.show()\n",
        "    \n",
        "    def reset(self):\n",
        "        self.map = self.reset_map\n",
        "        self.harry_pos = self.reset_harry_pos\n",
        "        return self.harry_pos[1] * self.size[1] + self.harry_pos[0] #10 * self.harry_pos[1] + self.harry_pos[1] #given state\n",
        "\n",
        "    def is_goal_state(self):\n",
        "        return self.harry_pos == self.sirius_pos\n",
        "    \n",
        "    def has_fallen_of_map(self):\n",
        "        x_range = np.array(range(self.size[0]))\n",
        "        y_range = np.array(range(self.size[1]))\n",
        "        return (self.harry_pos[0] not in x_range) or (self.harry_pos[1] not in y_range)\n",
        "    \n",
        "    def move_harry_right(self):\n",
        "        self.harry_pos = list(self.harry_pos)\n",
        "        self.harry_pos[0] += 1\n",
        "        self.harry_pos = list(self.harry_pos)\n",
        "        return self.get_move_result()\n",
        "\n",
        "    def move_harry_left(self):\n",
        "        self.harry_pos = list(self.harry_pos)\n",
        "        self.harry_pos[0] -= 1\n",
        "        self.harry_pos = list(self.harry_pos)\n",
        "        return self.get_move_result()\n",
        "    \n",
        "    def move_harry_up(self):\n",
        "        self.harry_pos = list(self.harry_pos)\n",
        "        self.harry_pos[1] -= 1\n",
        "        self.harry_pos = list(self.harry_pos)\n",
        "        return self.get_move_result()\n",
        "\n",
        "    def move_harry_down(self):\n",
        "        self.harry_pos = list(self.harry_pos)\n",
        "        self.harry_pos[1] += 1\n",
        "        self.harry_pos = tuple(self.harry_pos)\n",
        "        return self.get_move_result()\n",
        "    \n",
        "    def move_harry_up_right(self):\n",
        "        self.move_harry_up()\n",
        "        self.move_harry_right()\n",
        "        return self.get_move_result()\n",
        "\n",
        "    def move_harry_up_left(self):\n",
        "        self.move_harry_up()\n",
        "        self.move_harry_left()\n",
        "        return self.get_move_result()\n",
        "\n",
        "    def move_harry_down_right(self):\n",
        "        self.move_harry_down()\n",
        "        self.move_harry_right()\n",
        "        return self.get_move_result()\n",
        "\n",
        "    def move_harry_down_left(self):\n",
        "        self.move_harry_down()\n",
        "        self.move_harry_left()\n",
        "        return self.get_move_result()\n",
        "    # [7, 9] = (63)\n",
        "    \n",
        "    def get_move_result(self):\n",
        "        new_state = self.harry_pos[1] * self.size[1] + self.harry_pos[0]\n",
        "        if self.is_goal_state():\n",
        "            return new_state, self._rewards[\"goal\"], True\n",
        "        if self.has_fallen_of_map():\n",
        "            return new_state, self._rewards[\"fall\"], True\n",
        "        \n",
        "        self.map = create_map(self.size, self.harry_pos, self.sirius_pos)\n",
        "        return new_state, self._rewards[\"walk\"], False\n",
        "        \n",
        "    def step(self, action):\n",
        "        direction = self._action_to_direction[action]\n",
        "        if direction == \"left\":\n",
        "            new_state, reward, done = self.move_harry_left()\n",
        "        elif direction == \"right\":\n",
        "            new_state, reward, done = self.move_harry_right()\n",
        "        elif direction == \"up\":\n",
        "            new_state, reward, done = self.move_harry_up()\n",
        "        elif direction == \"down\":\n",
        "            new_state, reward, done = self.move_harry_down()\n",
        "        elif direction == \"up_right\":\n",
        "            new_state, reward, done = self.move_harry_up_right()\n",
        "        elif direction == \"up_left\":\n",
        "            new_state, reward, done = self.move_harry_up_left()\n",
        "        elif direction == \"down_right\":\n",
        "            new_state, reward, done = self.move_harry_down_right()\n",
        "        elif direction == \"down_left\":\n",
        "            new_state, reward, done = self.move_harry_down_left()\n",
        "            \n",
        "        # probability windy columns\n",
        "        if self.harry_pos[0] == 3:\n",
        "            random_number = np.random.rand()\n",
        "            if random_number <= self.prob_A:\n",
        "                new_state, reward, done = self.move_harry_up()\n",
        "            else:\n",
        "                new_state, reward, done = self.get_move_result()\n",
        "\n",
        "        if self.harry_pos[0] == 4:\n",
        "            random_number = np.random.rand()\n",
        "            if random_number <= self.prob_B:\n",
        "                new_state, reward, done = self.move_harry_up()\n",
        "                new_state, reward, done = self.move_harry_up()\n",
        "            else:\n",
        "                new_state, reward, done = self.get_move_result()\n",
        "\n",
        "        if self.harry_pos[0] == 5:\n",
        "            random_number = np.random.rand()\n",
        "            if random_number <= self.prob_C:\n",
        "                new_state, reward, done = self.move_harry_up()\n",
        "            else:\n",
        "                new_state, reward, done = self.get_move_result()\n",
        "\n",
        "        return new_state, reward, done\n",
        "    \n",
        "    def close(self):\n",
        "        clear_output(wait=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SwHri01bAkXS"
      },
      "source": [
        "Create Azkaban environment as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNZBdMK7AkXT"
      },
      "outputs": [],
      "source": [
        "map_size = (9, 7)\n",
        "init_pos = (1, 1)\n",
        "goal_pos = (7, 4)\n",
        "azkaban_map = create_map(map_size, init_pos, goal_pos)\n",
        "env = AzkabanEnviroment(azkaban_map, init_pos, goal_pos)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4O7Xs-U7AkXT"
      },
      "source": [
        "Render the environment, visualization of the current state of the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4-HLJzyAkXU",
        "outputId": "ce50b1b0-2d8c-47fe-be02-63039a6585b7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 370.286x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "env.render()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7kfPt7sKAkXU"
      },
      "source": [
        "Get states and actions for the lake\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gw4JzKLAkXV",
        "outputId": "e41caac7-7158-4c52-b341-153b58497e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 63)\n"
          ]
        }
      ],
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "\n",
        "print((action_space_size, state_space_size))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vz5vxQeuAkXV"
      },
      "source": [
        "Move the agent: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O94f5jdAkXV",
        "outputId": "fc5bb005-7edb-4b91-82e9-071571faf35a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "down\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 370.286x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "action = env.action_space.sample()\n",
        "state = env.reset() #*10\n",
        "new_state, reward, done = env.step(action)\n",
        "print(env.get_actions(action))\n",
        "env.render()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CagdIx5qAkXW"
      },
      "source": [
        "Initialize some parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BQQAef5AkXW",
        "outputId": "8074f1b0-bab7-4304-a456-f5692af54fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(63, 8)\n"
          ]
        }
      ],
      "source": [
        "num_episodes = 6000 #15000\n",
        "max_steps_per_episode = 100 #100\n",
        "\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.95\n",
        "\n",
        "rewards_avg = []\n",
        "\n",
        "#state_space_size = 120\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "\n",
        "print(q_table.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg6MMM71AkXW"
      },
      "source": [
        "# Q-Learning algorithm\n",
        "Our code defines a function called train_q_table that is responsible for training a Q table using the Q-learning reinforcement learning algorithm in a specific 'env' environment.\n",
        "\n",
        "The training process is done in several episodes. In each episode, the agent interacts with the environment by taking actions and updating the Q table based on the rewards received. A trade-off strategy between exploration and exploitation is used to balance the exploration of new stocks and the exploitation of the stocks that appear to be the most optimal so far.\n",
        "\n",
        "The Q table is initialized with zeros and is updated at each episode step using the equation of the Q-learning algorithm. In addition, a learning rate (learning_rate) and a discount factor (discount_rate) are used to adjust the influence of future rewards on updating the Q table values.\n",
        "\n",
        "After each episode, the reward earned is recorded and the exploration parameter (exploration_rate) is updated to gradually decrease exploration as more knowledge is accumulated.\n",
        "\n",
        "Finally, the updated Q table is returned at the end of the training process."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This algorithm is based on the Frozen-lake lab algorithm.\n",
        "\n",
        "It performs 6000 episodes, 100 times in order to view the average of the 100 times and verify if the agent is really learning to maximize its reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJCuPzEBAkXX"
      },
      "outputs": [],
      "source": [
        "def train_q_table(env, rewards_avg, iteration=100, learning_rate=0.95, discount_rate=0.95, num_episodes=6000, max_steps_per_episode=100):\n",
        "    for it in range(iteration):\n",
        "        print('average ', it)\n",
        "        rewards_all_episodes=[]\n",
        "\n",
        "        # exporation-exploitation trade-off params\n",
        "        exploration_rate = 1\n",
        "        max_exploration_rate = 1\n",
        "        min_exploration_rate = 0.01\n",
        "        exploration_decay_rate = 0.005\n",
        "\n",
        "        # init q table in zeros\n",
        "        q_table = np.zeros((state_space_size, action_space_size))\n",
        "\n",
        "        # iterate over the episodes\n",
        "        for episode in range(num_episodes):\n",
        "            state = env.reset()\n",
        "            done = False\n",
        "            rewards_current_episode = 0\n",
        "\n",
        "            # iterate over the steps for an episode\n",
        "            for step in range(max_steps_per_episode):\n",
        "                # Exploration-exploitation trade-off\n",
        "                exploration_rate_threshold = np.random.rand()\n",
        "                if exploration_rate_threshold <= exploration_rate:\n",
        "                    action = np.random.randint(0, action_space_size) # Exploration time\n",
        "                else:\n",
        "                    action = np.argmax(q_table[state]) # Explotation time\n",
        "\n",
        "                # Take action\n",
        "                new_state, reward, done = env.step(action)\n",
        "\n",
        "                # Update Q-table for Q(s,a)\n",
        "                q_table[state, action] = (1-learning_rate) * q_table[state, action] + learning_rate * (reward + discount_rate * np.max(q_table[new_state]))\n",
        "                \n",
        "                # transition next state\n",
        "                state = new_state\n",
        "                rewards_current_episode += reward\n",
        "\n",
        "                if done == True: \n",
        "                    break\n",
        "\n",
        "\n",
        "            # Exploration rate decay\n",
        "            exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * (np.exp(-exploration_decay_rate * episode)) #your code here\n",
        "            #env.render()\n",
        "            rewards_all_episodes.append(rewards_current_episode)\n",
        "\n",
        "        rewards_avg.append(rewards_all_episodes)\n",
        "    return q_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHtojLumAkXX",
        "outputId": "79b84557-9ae5-42fc-9776-a025e9eaa62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "average  0\n",
            "average  1\n",
            "average  2\n",
            "average  3\n",
            "average  4\n",
            "average  5\n",
            "average  6\n",
            "average  7\n",
            "average  8\n",
            "average  9\n",
            "average  10\n",
            "average  11\n",
            "average  12\n",
            "average  13\n",
            "average  14\n",
            "average  15\n",
            "average  16\n",
            "average  17\n",
            "average  18\n",
            "average  19\n",
            "average  20\n",
            "average  21\n",
            "average  22\n",
            "average  23\n",
            "average  24\n",
            "average  25\n",
            "average  26\n",
            "average  27\n",
            "average  28\n",
            "average  29\n",
            "average  30\n",
            "average  31\n",
            "average  32\n",
            "average  33\n",
            "average  34\n",
            "average  35\n",
            "average  36\n",
            "average  37\n",
            "average  38\n",
            "average  39\n",
            "average  40\n",
            "average  41\n",
            "average  42\n",
            "average  43\n",
            "average  44\n",
            "average  45\n",
            "average  46\n",
            "average  47\n",
            "average  48\n",
            "average  49\n",
            "average  50\n",
            "average  51\n",
            "average  52\n",
            "average  53\n",
            "average  54\n",
            "average  55\n",
            "average  56\n",
            "average  57\n",
            "average  58\n",
            "average  59\n",
            "average  60\n",
            "average  61\n",
            "average  62\n",
            "average  63\n",
            "average  64\n",
            "average  65\n",
            "average  66\n",
            "average  67\n",
            "average  68\n",
            "average  69\n",
            "average  70\n",
            "average  71\n",
            "average  72\n",
            "average  73\n",
            "average  74\n",
            "average  75\n",
            "average  76\n",
            "average  77\n",
            "average  78\n",
            "average  79\n",
            "average  80\n",
            "average  81\n",
            "average  82\n",
            "average  83\n",
            "average  84\n",
            "average  85\n",
            "average  86\n",
            "average  87\n",
            "average  88\n",
            "average  89\n",
            "average  90\n",
            "average  91\n",
            "average  92\n",
            "average  93\n",
            "average  94\n",
            "average  95\n",
            "average  96\n",
            "average  97\n",
            "average  98\n",
            "average  99\n"
          ]
        }
      ],
      "source": [
        "# Applying Q-learning\n",
        "walk_reward = -1\n",
        "fall_reward = -10\n",
        "goal_reward = 150\n",
        "\n",
        "env.reset()\n",
        "env.set_rewards(walk_reward , fall_reward, goal_reward)\n",
        "\n",
        "rewards_avg_test = []\n",
        "iteration = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.95\n",
        "num_episodes = 6000 #15000\n",
        "max_steps_per_episode = 100 #100\n",
        "q_table_1 = train_q_table(env, rewards_avg_test, iteration, learning_rate, discount_rate, num_episodes, max_steps_per_episode)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Find the optimal policy (graph every action that the agent can take) and graph the averag Reward Over Time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4h3Tw-CBnJz"
      },
      "source": [
        "# Visualization\n",
        "Here we can see how the performance of agent H improves as more training episodes are performed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo8FbOjpAkXX"
      },
      "outputs": [],
      "source": [
        "def plot_rewards_episodes(rewards_avg, num_episodes):\n",
        "    x = [i for i in range(0, num_episodes)]\n",
        "    y = np.mean(rewards_avg, axis=0)\n",
        "    plt.xlabel('Episodes')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.plot(x, y,'o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4_aB6mRAkXY",
        "outputId": "efa7dacd-e168-4662-df02-af8ad44ce521"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_rewards_episodes(rewards_avg_test, num_episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIgJYpTwAkXY",
        "outputId": "22af63ce-4e23-4ea5-b646-dabfb5135e02"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 370.286x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrb3XmjxAkXY",
        "outputId": "b7cf291c-0839-4326-bb53-f0b0eebee421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "********Q-table********\n",
            "\n",
            "[[-3.43900000e+00 -2.83238461e+00 -4.09510000e+00  2.51427762e+01\n",
            "  -4.68559000e+00 -4.09510000e+00 -2.92256750e+00 -4.19010000e+00]\n",
            " [-6.86189404e+00  6.95507370e+01 -2.88259017e+00 -2.87544626e+00\n",
            "  -5.21703100e+00 -6.12579511e+00 -2.86237987e+00 -2.91537874e+00]\n",
            " [-5.21703100e+00 -2.86245254e+00 -2.85076275e+00 -5.89284970e+00\n",
            "  -4.68559000e+00 -6.12579511e+00 -2.90156586e+00  7.49256011e+01]\n",
            " [-4.68559000e+00 -3.05804712e+00 -3.08761530e+00 -3.43900000e+00\n",
            "  -5.21703100e+00 -5.69532790e+00 -4.68559000e+00  3.10793441e+01]\n",
            " [-4.68559000e+00 -2.55268527e+00 -3.43900000e+00 -3.43900000e+00\n",
            "  -2.71000000e+00 -3.43900000e+00  2.80949450e+01 -2.26470118e+00]\n",
            " [-4.09510000e+00 -1.79881032e+00 -2.82668866e+00 -1.76669338e+00\n",
            "  -2.71000000e+00 -1.90000000e+00  8.98757645e+01 -3.43900000e+00]\n",
            " [-1.90000000e+00  8.82865634e+00 -1.90000000e+00 -1.47636407e+00\n",
            "  -2.22793843e+00 -1.90000000e+00 -1.44798968e+00 -1.40417814e+00]\n",
            " [-4.05358163e+00 -3.15714926e+00 -5.33802311e+00 -3.27878994e+00\n",
            "  -3.25229458e+00 -6.12579511e+00  3.52091727e+01 -7.71232075e+00]\n",
            " [ 1.31786412e+01  4.20095497e+01  4.47441665e+00  3.33765544e+01\n",
            "   4.16234144e+01  3.04893467e+00  9.67835694e+01  7.71209208e+00]\n",
            " [-2.70020875e+00  8.62426545e+01 -2.79493339e+00 -2.73004443e+00\n",
            "  -7.17570464e+00 -2.74569074e+00 -2.71304973e+00 -2.76837659e+00]\n",
            " [-2.91714262e+00 -2.38044336e+00 -2.35642294e+00 -4.12009798e+00\n",
            "  -3.64689166e+00 -2.46407616e+00 -2.37941075e+00  8.95292059e+01]\n",
            " [-1.90000000e+00 -1.30294506e+00 -1.34865359e+00 -1.26026108e+00\n",
            "  -4.09510000e+00 -1.90000000e+00  1.20347846e+02 -1.23293326e+00]\n",
            " [-1.90000000e+00 -1.07290840e+00 -1.90000000e+00 -7.04359743e-01\n",
            "  -1.10910182e+00 -2.71000000e+00  1.31373135e+02 -1.05835708e+00]\n",
            " [-1.08928672e+00  1.27375551e+02 -1.31146351e+00 -1.22389915e+00\n",
            "  -1.30631522e+00 -2.71000000e+00 -1.28362393e+00 -1.12784774e+00]\n",
            " [-2.93127934e+00  4.42960514e+01 -6.61601401e+00 -2.60631200e+00\n",
            "  -2.89954052e+00 -8.48033057e+00 -2.88994731e+00 -6.87994404e+00]\n",
            " [-2.67892401e+00 -2.67829414e+00 -2.97883154e+00 -2.98242501e+00\n",
            "   2.34662957e+00 -3.33294926e+00  9.95825305e+01 -2.66631621e+00]\n",
            " [ 1.51509207e+01  1.02840100e+02  3.30387267e+01  3.49996307e+01\n",
            "  -1.24634744e+00  4.60856449e+01  2.53151751e+01  2.70190197e+01]\n",
            " [-1.71474211e+00 -1.77023533e+00 -1.70432742e+00 -1.80308817e+00\n",
            "  -2.03851000e+00 -1.83869741e+00  1.05691570e+02 -1.83672491e+00]\n",
            " [ 8.82409522e+00  2.81788276e+01  3.04841294e+01  4.30913694e+01\n",
            "   7.27106282e+00  8.44230043e+00  1.24057883e+02  2.49910845e+01]\n",
            " [ 2.82472365e+01  4.87627422e+01  1.79511341e+00  1.31639877e+02\n",
            "   2.71491758e+01 -4.09510000e+00  2.28877399e+01  2.99902676e+01]\n",
            " [ 5.07953910e+01  3.92207338e+01  2.61344942e+01  3.47341899e+01\n",
            "   5.64492323e+00  3.57389092e+01  1.39620923e+02  7.57783323e+01]\n",
            " [-2.67653919e+00 -2.54760853e+00 -3.48022050e+00 -2.58693386e+00\n",
            "   8.79502976e+01 -5.96189404e+00 -2.61789228e+00 -5.64424079e+00]\n",
            " [-2.43770234e+00 -2.39378202e+00 -2.40497601e+00 -2.36964677e+00\n",
            "   8.32725418e+01 -2.43762011e+00 -2.51637494e+00 -2.37877451e+00]\n",
            " [ 5.75205567e+01  1.41197572e+01  2.95067623e+01  5.60948006e+01\n",
            "   3.84353630e+01  3.42189245e+01  1.09267277e+02 -1.54342386e-01]\n",
            " [ 2.11731242e+01  4.55012278e+01  4.14170431e+01  2.07791472e+01\n",
            "   2.05587112e+01  4.99810510e+01  1.16510832e+02  1.04720627e+01]\n",
            " [-6.06159956e-01 -5.89078903e-01  7.04314547e+00  1.19331556e+01\n",
            "   3.18980014e+01 -7.19072694e-01  1.20117324e+02 -5.66835309e-01]\n",
            " [ 2.62175076e+01  2.36081482e+01  1.02032046e+01  2.42247490e+01\n",
            "   1.31639877e+02  2.11732925e+01  3.47547173e+00  4.00103298e+01]\n",
            " [-2.10610250e-01 -2.71000000e-01 -3.34237913e-01 -4.73329084e-01\n",
            "  -2.48548731e-01 -3.01902629e-01 -4.28672033e-01  1.14266247e+02]\n",
            " [ 1.67754543e+01  1.48022025e+02  4.11874376e+01  5.99049916e+00\n",
            "   1.79037500e+01  4.31105665e+01  1.21304796e+01 -1.16057375e-01]\n",
            " [-2.23793840e+00 -2.25410187e+00 -2.20982359e+00 -2.82373593e+00\n",
            "  -2.18471996e+00  3.54750775e+01 -2.66115259e+00 -2.22216727e+00]\n",
            " [-1.52367246e+00 -1.46203155e+00 -1.48859291e+00 -1.48386458e+00\n",
            "   5.70685191e+01 -1.47710002e+00 -1.45844372e+00 -1.51075278e+00]\n",
            " [ 8.38497114e+00 -6.45274133e-01 -9.98116550e-01  1.08465627e+01\n",
            "  -9.27882413e-01  9.39458484e+00  1.15273702e+02 -1.06116993e+00]\n",
            " [ 1.96405716e+00 -2.98876244e-01  1.05897051e+01  1.21905386e+02\n",
            "   3.34120291e+01 -3.94536165e-01 -3.14420741e-02  2.04162707e+01]\n",
            " [-1.37721056e-01 -1.90000000e-01 -1.18050000e-01 -1.00000000e-01\n",
            "  -7.31120500e-02 -1.40618200e-01 -1.00000000e-01  1.15127075e+02]\n",
            " [ 3.75871211e+01 -1.00000000e-01  1.23157883e+01 -2.60976530e-01\n",
            "  -2.89053303e-01 -1.49624049e-01 -2.83215684e-01 -1.00000000e-01]\n",
            " [-2.29611911e+00 -2.09267582e+00 -7.71232075e+00 -2.08207929e+00\n",
            "  -2.15200202e+00 -8.63160358e+00 -2.10828339e+00 -9.35389181e+00]\n",
            " [-2.11112705e+00 -2.08102305e+00 -2.14265948e+00 -2.92675596e+00\n",
            "  -3.00593196e+00  6.43206076e+01 -2.30941850e+00 -2.22841861e+00]\n",
            " [-1.35206135e+00 -1.22358625e+00 -1.33797993e+00 -1.25207557e+00\n",
            "  -1.20594232e+00 -1.28314189e+00 -1.20735240e+00 -1.34017134e+00]\n",
            " [-7.17465391e-01 -5.92549813e-01 -6.85816100e-01 -6.16902751e-01\n",
            "   1.11795442e+01 -6.95500390e-01 -5.69176711e-01 -6.43799751e-01]\n",
            " [-1.65364699e-01 -1.10804231e-01  1.07899682e+01 -9.20784981e-02\n",
            "   1.22896657e+02  0.00000000e+00  1.07854989e+00  0.00000000e+00]\n",
            " [ 2.35709978e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [-1.00000000e-01 -1.00000000e-01 -1.00000000e-01  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [-2.21930156e+00 -3.43900000e+00 -3.43900000e+00 -2.20939438e+00\n",
            "  -9.13617581e-01 -3.43900000e+00 -3.43900000e+00 -2.71000000e+00]\n",
            " [-1.82304167e+00 -5.21703100e+00 -1.93122278e+00 -2.01219581e+00\n",
            "  -2.42204337e+00 -1.82081800e+00 -4.09510000e+00 -6.12579511e+00]\n",
            " [-1.04881399e+00 -2.71000000e+00 -1.04658001e+00 -1.07478233e+00\n",
            "  -1.06148273e+00 -1.19257977e+00 -1.42170310e+00 -1.90000000e+00]\n",
            " [-2.38919474e-01 -1.99500000e-01 -2.46167292e-01 -1.90000000e-01\n",
            "  -2.44817205e-01 -1.54487440e-01 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.18050000e-01 -1.00000000e-01  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [-1.00000000e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "# Print updated Q-table\n",
        "print(\"\\n\\n********Q-table********\\n\")\n",
        "print(q_table_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbrivNYEAkXZ",
        "outputId": "98eb6ef8-460a-452f-af7e-602681f49316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3 1 7 7 6 6 1 6 6 1 7 6 6 1 1 6 1 6 6 3 6 4 4 6 6 6 4 7 1 5 4 6 3 7 0 3\n",
            "  5 4 4 4 0 3 4 5 2 5 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "def best_pos_max(matrix):\n",
        "    posiciones_maximas = np.argmax(matrix, axis=1)\n",
        "    matriz_resultante = posiciones_maximas.reshape(1, -1)\n",
        "    return matriz_resultante\n",
        "\n",
        "pos_best_moves = best_pos_max(q_table_1)\n",
        "print(pos_best_moves)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4UpBcmYbBs-O"
      },
      "source": [
        "Here, we identify  the best actions for each state based on the Q values in the q_table_1 matrix, these Q values represent the expected reward for taking those actions in each state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-0GEA2PAkXZ",
        "outputId": "b14a18c4-8fc0-4ec6-d85b-e167209e6e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 25.14277621]\n",
            " [ 69.55073697]\n",
            " [ 74.92560113]\n",
            " [ 31.07934406]\n",
            " [ 28.09494502]\n",
            " [ 89.87576453]\n",
            " [  8.82865634]\n",
            " [ 35.20917269]\n",
            " [ 96.78356937]\n",
            " [ 86.24265446]\n",
            " [ 89.52920593]\n",
            " [120.34784551]\n",
            " [131.37313523]\n",
            " [127.37555126]\n",
            " [ 44.29605139]\n",
            " [ 99.58253049]\n",
            " [102.84009981]\n",
            " [105.69157031]\n",
            " [124.05788341]\n",
            " [131.63987727]\n",
            " [139.62092344]\n",
            " [ 87.95029755]\n",
            " [ 83.27254178]\n",
            " [109.26727658]\n",
            " [116.51083174]\n",
            " [120.11732434]\n",
            " [131.63987727]\n",
            " [114.26624671]\n",
            " [148.02202468]\n",
            " [ 35.47507749]\n",
            " [ 57.06851914]\n",
            " [115.27370206]\n",
            " [121.90538583]\n",
            " [115.12707492]\n",
            " [ 37.58712111]\n",
            " [ -2.08207929]\n",
            " [ 64.3206076 ]\n",
            " [ -1.20594232]\n",
            " [ 11.17954425]\n",
            " [122.89665712]\n",
            " [ 23.57099785]\n",
            " [  0.        ]\n",
            " [ -0.91361758]\n",
            " [ -1.820818  ]\n",
            " [ -1.04658001]\n",
            " [ -0.15448744]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]\n",
            " [  0.        ]]\n"
          ]
        }
      ],
      "source": [
        "index_array = np.argmax(q_table_1, axis=-1)\n",
        "best_moves = np.take_along_axis(q_table_1, np.expand_dims(index_array, axis=-1), axis=-1)\n",
        "print(best_moves)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aeCJwlkUCZYT"
      },
      "source": [
        "The following code finds the best actions (action indices) for each state based on the Q values stored in the q_table_1 array and stores them in the state_best_actions list. Then, it creates an arrow_matrix matrix that shows the arrow representations corresponding to the best actions for each state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16M2lgSCAkXZ",
        "outputId": "c3440b3b-3d51-441c-d68d-856c30d1f9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3, 1, 7, 7, 6, 6, 1, 6, 6, 1, 7, 6, 6, 1, 1, 6, 1, 6, 6, 3, 6, 4, 4, 6, 6, 6, 4, 7, 1, 5, 4, 6, 3, 7, 0, 3, 5, 4, 4, 4, 0, 3, 4, 5, 2, 5, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[[3 1 7 7 6 6 1 6 6]\n",
            " [1 7 6 6 1 1 6 1 6]\n",
            " [6 3 6 4 4 6 6 6 4]\n",
            " [7 1 5 4 6 3 7 0 3]\n",
            " [5 4 4 4 0 3 4 5 2]\n",
            " [5 2 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# action_space = [up, down, left, right, ...] \n",
        "state_best_actions =[]\n",
        "arrow_matrix = []\n",
        "for i in range(q_table_1.shape[0]):\n",
        "    max_pos = np.argmax(q_table_1[i])\n",
        "    state_best_actions.append(max_pos)\n",
        "arrow_matrix = np.array(state_best_actions).reshape(7,9)\n",
        "\n",
        "print(state_best_actions)\n",
        "print(arrow_matrix)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9yXr4H6SC2Mh"
      },
      "source": [
        "Here we extract the best actions from the Q table and represent them in a matrix that shows the directions of the actions for each state on the map"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "if8w0bruDgxv"
      },
      "source": [
        "First an empty list named state_best_actions is created to store the best actions (action indices) for each state and an empty array named arrow_matrix to store the arrow representations corresponding to the best actions for each state.\n",
        "Then, in a loop, the rows of the q_table array are traversed and the function np.argmax(q_table[i]) is used to find the index of the action with the maximum Q value for each state i, this index represents the best action for that state.\n",
        "The best action index is added to the state_best_actions list. Also, convert the state_best_actions list to a NumPy array and\n",
        "reshape(map.shape[0], map.shape[1]) is used to shape the arrow_matrix using the dimensions of the map.\n",
        "\n",
        "Finally, the arrow_matrix matrix is returned, representing the best actions for each map state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osceUMHXAkXZ"
      },
      "outputs": [],
      "source": [
        "def policies_matrix(q_table, map):\n",
        "    state_best_actions =[]\n",
        "    arrow_matrix = []\n",
        "    for i in range(q_table.shape[0]):\n",
        "        max_pos = np.argmax(q_table[i])\n",
        "        state_best_actions.append(max_pos)\n",
        "    arrow_matrix = np.array(state_best_actions).reshape(map.shape[0], map.shape[1])\n",
        "    return arrow_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueXMNHO6AkXa",
        "outputId": "e18bf4c9-7bc5-4c45-8228-0df34c9982ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3 1 7 7 6 6 1 6 6]\n",
            " [1 7 6 6 1 1 6 1 6]\n",
            " [6 3 6 4 4 6 6 6 4]\n",
            " [7 1 5 4 6 3 7 0 3]\n",
            " [5 4 4 4 0 3 4 5 2]\n",
            " [5 2 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "policies_matrix = policies_matrix(q_table_1, map)\n",
        "print(policies_matrix)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UuWyeIZgHh__"
      },
      "source": [
        "# Optimal Policy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WTgH84D7HgPb"
      },
      "source": [
        "The show_optimal_policy function displays a graphical representation of the map and the optimal policies for each state on the map. Colors and Unicode arrows are used to visualize different types of cells and the best actions to take from each state. The map is displayed with a color palette representing empty spaces, the starting point, and the goal. Arrow texts are added in each cell of the map to indicate the corresponding best action. Parameters such as row and column labels, color palette, normalization, and Unicode arrows are used to configure and customize the map's rendering and optimal policies. At the end, the resulting graph is displayed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K_pi3jLAkXa"
      },
      "outputs": [],
      "source": [
        "def show_optimal_policy(map):\n",
        "    row_labels, col_labels = range(map.shape[0]), range(map.shape[1])\n",
        "    cmap = ListedColormap(['white', 'blueviolet', 'yellowgreen'])\n",
        "    norm = Normalize(vmin=0, vmax=2) # normalization for color values using\n",
        "    plt.matshow(map, cmap=cmap, norm=norm)\n",
        "    plt.xticks(col_labels, col_labels)\n",
        "    plt.yticks(row_labels, row_labels)\n",
        "    plt.grid(color='k', linewidth=1)\n",
        "    init = np.where(map == 1)\n",
        "    plt.text(init[1][0], init[0][0], 'H', ha='center', va='center', color='white', weight='bold', backgroundcolor='blueviolet', fontsize=20)\n",
        "    goal = np.where(map == 2)\n",
        "    plt.text(goal[1][0], goal[0][0], 'S', ha='center', va='center', color='white', weight='bold', backgroundcolor='yellowgreen', fontsize=20)\n",
        "\n",
        "    arrows = ['\\u2191', '\\u2193', '\\u2190', '\\u2192', '\\u2197', '\\u2196', '\\u2199', '\\u2198']\n",
        "    for i, row in enumerate(map):\n",
        "        for j, cell in enumerate(row):\n",
        "            if cell == 0:\n",
        "                plt.text(j, i, arrows[0], ha='center', va='center', color='black', weight='bold', backgroundcolor='lightblue', fontsize=20)\n",
        "            elif cell == 1:\n",
        "                plt.text(j, i, arrows[1], ha='center', va='center', color='black', weight='bold', backgroundcolor='lightblue', fontsize=20)\n",
        "            elif cell == 2:\n",
        "                plt.text(j, i, arrows[2], ha='center', va='center', color='black', backgroundcolor='lightblue', fontsize=20)\n",
        "            elif cell == 3:\n",
        "                plt.text(j, i, arrows[3], ha='center', va='center', color='black', backgroundcolor='lightblue', fontsize=20)\n",
        "            elif cell == 4:\n",
        "                plt.text(j, i, arrows[4], ha='center', va='center', color='black', backgroundcolor='lightblue', fontsize=20)\n",
        "            elif cell == 5:\n",
        "                plt.text(j, i, arrows[5], ha='center', va='center', color='black', backgroundcolor='lightblue', fontsize=20)\n",
        "            elif cell == 6:\n",
        "                plt.text(j, i, arrows[6], ha='center', va='center', color='black', backgroundcolor='lightblue', fontsize=20)\n",
        "            elif cell == 7:\n",
        "                plt.text(j, i, arrows[7], ha='center', va='center', color='black', backgroundcolor='lightblue', fontsize=20)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLwdmcp1AkXa",
        "outputId": "fc83e90d-bb12-43a6-ca92-fb815554a7e0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 370.286x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK-6-b3QAkXb",
        "outputId": "dd781c12-72b6-430e-f6b6-26b08ff6aa36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Harry init action: down_left\n",
            "Harry end action: up_left\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 370.286x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Harry init action:', actions[arrow_matrix[1][1]])\n",
        "print('Harry end action:', actions[arrow_matrix[4][7]])\n",
        "arrow_matrix[1][1] = -2\n",
        "arrow_matrix[4][7] = -3\n",
        "show_optimal_policy(arrow_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoaPdaXwAkXm",
        "outputId": "51a745ec-f0b6-4856-e1fe-fa023fc79db6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nfor episode in range(50):\\n    env_copy = copy(env)\\n    state = env_copy.reset()\\n    done = False\\n    print(\"*****EPISODE \", episode+1, \"*****\\n\\n\\n\\n\")\\n    time.sleep(1)\\n    \\n    for step in range(max_steps_per_episode):        \\n        clear_output(wait=True)\\n        env_copy.render()\\n        time.sleep(0.3)\\n        \\n        action = np.argmax(q_table[state,:])        \\n        new_state, reward, done = env_copy.step(action)\\n        \\n        if done:\\n            clear_output(wait=True)\\n            env_copy.render()\\n            if reward == goal_reward:\\n                print(\"****You reached the goal!****\")\\n                time.sleep(3)\\n            elif reward == fall_reward:\\n                print(\"****You fell through the map!****\")\\n                time.sleep(1)\\n                clear_output(wait=True)\\n\\n            break\\n            \\n        state = new_state\\n        #env.close()\\n'"
            ]
          },
          "execution_count": 524,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "for episode in range(50):\n",
        "    env_copy = copy(env)\n",
        "    state = env_copy.reset()\n",
        "    done = False\n",
        "    print(\"*****EPISODE \", episode+1, \"*****\\n\\n\\n\\n\")\n",
        "    time.sleep(1)\n",
        "    \n",
        "    for step in range(max_steps_per_episode):        \n",
        "        clear_output(wait=True)\n",
        "        env_copy.render()\n",
        "        time.sleep(0.3)\n",
        "        \n",
        "        action = np.argmax(q_table[state,:])        \n",
        "        new_state, reward, done = env_copy.step(action)\n",
        "        \n",
        "        if done:\n",
        "            clear_output(wait=True)\n",
        "            env_copy.render()\n",
        "            if reward == goal_reward:\n",
        "                print(\"****You reached the goal!****\")\n",
        "                time.sleep(3)\n",
        "            elif reward == fall_reward:\n",
        "                print(\"****You fell through the map!****\")\n",
        "                time.sleep(1)\n",
        "                clear_output(wait=True)\n",
        "\n",
        "            break\n",
        "            \n",
        "        state = new_state\n",
        "        #env.close()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5eoo-HpAkXm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mytest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
